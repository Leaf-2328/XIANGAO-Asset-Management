{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "获取20210512数据。。。\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, unicode_literals\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "from pandas import Series\n",
    "from datetime import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import time \n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "import pdb\n",
    "from datetime import date\n",
    "import sys\n",
    "from data_provider.datafeed.quote_feed import QuoteFeed\n",
    "from data_provider.nestlib.trading_cal import TradeCal\n",
    "from data_provider.datafeed.universe import Universe\n",
    "from data_provider.nestlib.market_info import Frequency\n",
    "from data_provider.datafeed.financial_feed import FinancialFeed\n",
    "from data_provider.datafeed.finance_utils import ttmContinues, ttmDiscrete\n",
    "from smartbeta.smartfactor import SmartFactor\n",
    "from index_li import mao_40_li\n",
    "from index_li import institutions_baotuan_50_li\n",
    "import matplotlib.pyplot as plt\n",
    "uni = Universe()\n",
    "tc = TradeCal()\n",
    "\n",
    "tc_handle = TradeCal()\n",
    "uni_handle = Universe()\n",
    "\n",
    "now_day = date.today().strftime('%Y%m%d')\n",
    "if tc_handle.is_trading_day(now_day) == True:\n",
    "    print('获取'+now_day+'数据。。。')\n",
    "else:\n",
    "    print('今天不是交易日 获取数据失败！')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_ipo_stocks(date):\n",
    "    ipo_df = uni.get_all_ipo_info()\n",
    "    limit = tc.shift_date(date, 30, direction='backward')\n",
    "    new_ipo_stocks_df = ipo_df[ipo_df['ipo_date']>int(limit)]\n",
    "    new_ipo_stocks_li = new_ipo_stocks_df['ticker'].tolist()\n",
    "    return new_ipo_stocks_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_all_stocks(date):\n",
    "#     print('正在获取每日股票总数(除去新股)。。。。。。')\n",
    "    all_stocks_li = uni.get_a_share_by_date(date)\n",
    "    all_stocks_li = list(set(all_stocks_li)-set(get_new_ipo_stocks(date)))\n",
    "    return all_stocks_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_up_stocks_all_stcoks(begin_date,end_date):\n",
    "    print('正在获取每日上涨的股票数和每日股票总数(除去新股)。。。。。。')\n",
    "    df = SmartFactor('dailyreturn').load(begin_date,end_date)\n",
    "    gb_df_data = df.groupby('tdate')\n",
    "    date_number_li = []\n",
    "    for any_date,date_df in tqdm(gb_df_data):\n",
    "        date_df = date_df.copy()\n",
    "        date_df = date_df[date_df['factor_value']>0]\n",
    "        date_df = date_df.drop(date_df[date_df['security_code'].isin(get_new_ipo_stocks(any_date))].index)\n",
    "        number = len(date_df)\n",
    "        number_all = len(get_number_of_all_stocks(any_date))\n",
    "        date_number_li.append([any_date,number,number_all])\n",
    "    result = pd.DataFrame(date_number_li,columns=['date','number_of_up_stocks','number_of_all_stocks'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_dailyreturn(ticker,begin_date,end_date):    \n",
    "    tickers = ticker\n",
    "    shift_back_begin_date = tc.shift_date(begin_date, 1, direction='backward')\n",
    "    week_quote = QuoteFeed(\n",
    "        universe_ticker=tickers,\n",
    "        begin_day=shift_back_begin_date,\n",
    "        end_day=end_date,\n",
    "        tracking_freq=86400,\n",
    "        is_index=True,\n",
    "    )\n",
    "    week_quote.load_feed()\n",
    "    df = week_quote.get_index_quote()\n",
    "    df.loc[:,'yesterday_close'] = df['close'].shift(1)\n",
    "    df = df.dropna()\n",
    "    df.loc[:,'dailyreturn'] = (df['close']-df['yesterday_close'])/df['yesterday_close']\n",
    "    return df[['datetime_str','dailyreturn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median_dailyrertun_of_all_market(begin_date,end_date):\n",
    "    all_stocks_df = SmartFactor('dailyreturn').load(begin_date,end_date)\n",
    "    gb_df_data = all_stocks_df.groupby('tdate')\n",
    "    zz500_df = get_index_dailyreturn('000905.SH',begin_date,end_date)\n",
    "    hs300_df = get_index_dailyreturn('000300.SH',begin_date,end_date)\n",
    "    date_return_li = []\n",
    "    for any_date,date_df in tqdm(gb_df_data):\n",
    "        date_df = date_df.copy()\n",
    "        median_return = date_df['factor_value'].median()\n",
    "        hs_300_return = hs300_df.loc[hs300_df[hs300_df['datetime_str']==any_date].index,'dailyreturn'].values[0]\n",
    "        zz_500_rertun = zz500_df.loc[zz500_df[zz500_df['datetime_str']==any_date].index,'dailyreturn'].values[0]\n",
    "        date_return_li.append([any_date,median_return,hs_300_return,zz_500_rertun])\n",
    "    result = pd.DataFrame(date_return_li,columns=['date','all_market_median_return','hs_300_return','zz_500_return'])\n",
    "    return result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_special_index_return(ticker_li,begin_date,end_date):\n",
    "    all_stocks_df = SmartFactor('dailyreturn').load(begin_date,end_date)\n",
    "    special_index_df = all_stocks_df.loc[all_stocks_df[all_stocks_df['security_code'].isin(ticker_li)].index,:]\n",
    "    data = special_index_df.groupby('tdate')\n",
    "    return_li = []\n",
    "    for any_date,date_df in data:\n",
    "        mean_return = date_df['factor_value'].mean()\n",
    "        return_li.append([any_date,mean_return])\n",
    "    return_df = pd.DataFrame(return_li,columns=['date','special_index_mean_dailyreturn'])\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_open_auction_amount(begin_date,end_date):\n",
    "    trading_date_li = tc.get_trading_day_list(begin_date,end_date)\n",
    "    dir_path = '/home/jovyan/work/share/call_auction_data/'\n",
    "    data_li = []\n",
    "    ticker_number_li = []\n",
    "    for td in tqdm(trading_date_li):\n",
    "        ticker_number = 0\n",
    "        abs_path = dir_path + td + '.pkl'\n",
    "        if not os.path.exists(abs_path):\n",
    "            continue\n",
    "\n",
    "        if os.path.getsize(abs_path)/(1024*1024.0) < 8:  # 小于8M的数据认为是异常数据\n",
    "            continue\n",
    "\n",
    "\n",
    "        with open(dir_path+'{0}.pkl'.format(td), 'rb') as fp:\n",
    "            tick_dict = pickle.load(fp)\n",
    "\n",
    "        geye_ret = {}\n",
    "        for tk, tick_ls in tick_dict.items():\n",
    "            open_tick = None\n",
    "\n",
    "            for idx in range(len(tick_ls)):\n",
    "\n",
    "                if tick_ls[idx]['nTime']>93000000:\n",
    "                    break\n",
    "\n",
    "                if tick_ls[idx]['nTime']>=92000000 and tick_ls[idx]['nTime']<=92457000:\n",
    "                    open_tick = tick_ls[idx]\n",
    "                    ticker_number = ticker_number + 1\n",
    "\n",
    "        ticker_number_li.append([td,ticker_number])\n",
    "    df_ticker = pd.DataFrame(ticker_number_li,columns=['date','open_auction_ticker_number'])\n",
    "    return df_ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_market_amount(begin_date,end_date):\n",
    "    all_tickers = uni.get_a_share_in_period(begin_date, end_date)\n",
    "    quote = QuoteFeed(\n",
    "    universe_ticker=all_tickers,\n",
    "    begin_day=begin_date,\n",
    "    end_day=end_date,\n",
    "    tracking_freq=86400,\n",
    "    use_cache=True,\n",
    "    )\n",
    "    quote.load_feed()\n",
    "    all_df = quote.get_stock_quote()\n",
    "    data = all_df.groupby('datetime')\n",
    "    amount_li = []\n",
    "    for any_date,date_df in data:\n",
    "        total_amount = date_df['amount'].sum()\n",
    "        mao_40_amount =date_df.loc[date_df[date_df['ticker'].isin(mao_40_li)].index,'amount'].sum()\n",
    "        institutions_baotuan_50_amount =date_df.loc[date_df[date_df['ticker'].isin(institutions_baotuan_50_li)].index,'amount'].sum()\n",
    "        amount_li.append([any_date,mao_40_amount,institutions_baotuan_50_amount,total_amount])\n",
    "    result = pd.DataFrame(amount_li,columns=['date','mao_40_amount','institutions_baotuan_50_amount','all_stocks_total_daily_amount'])\n",
    "    result.loc[:,'mao_40_ratio'] = result['mao_40_amount']/result['all_stocks_total_daily_amount']\n",
    "    result.loc[:,'institutions_baotuan_50_ratio'] = result['institutions_baotuan_50_amount']/result['all_stocks_total_daily_amount']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_limit_up_down_number(begin_date,end_date):\n",
    "    all_df = uni.get_limit_up_down(begin_date,end_date)\n",
    "    gb_data = all_df.groupby('time')\n",
    "    data_li = []\n",
    "    for day,day_df in gb_data:\n",
    "        day_df = day_df.copy()\n",
    "        zt_number = len(day_df[(day_df['iszt']==1)|(day_df['iszt2']==1)])\n",
    "        dt_number = len(day_df[(day_df['isdt']==1)|(day_df['isdt2']==1)])\n",
    "        data_li.append([day,zt_number,dt_number])\n",
    "    zt_dt_number_df = pd.DataFrame(data_li,columns=['date','zhangting_number','dieting_number'])\n",
    "    return zt_dt_number_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_fin_sec_info(begin_date,end_date):\n",
    "#     tradeday_li = tc.get_trading_day_list(begin_date,end_date)\n",
    "#     df = pd.read_csv('fin_sec_info.csv')\n",
    "#     result = df.loc[df[df['date'].isin(tradeday_li)].index,:]\n",
    "#     result = result.sort_values(by='date',ascending=False)\n",
    "#     return result[['date','finval_sum','secval_sum','finval_secval_sum','fin_sec_ratio']] #日期,融资余额,融券余额,融资融券余额,融资占融资融券余额比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "today = datetime.now().strftime('%Y%m%d')\n",
    "begin_day = today\n",
    "end_day = today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在获取每日上涨的股票数和每日股票总数(除去新股)。。。。。。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dailyreturn time cost 1.41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.75it/s]\n",
      "/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py:357: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dailyreturn time cost 1.42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 87.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dailyreturn time cost 1.20s\n",
      "loading dailyreturn time cost 1.17s\n",
      "正在使用hdf5行情！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n"
     ]
    }
   ],
   "source": [
    "df1 = get_number_of_up_stocks_all_stcoks(begin_day,end_day)\n",
    "\n",
    "df2 = get_index_dailyreturn('000905.SH',begin_day,end_day)\n",
    "df2 = df2.rename(columns={'dailyreturn':'zz500_dailyreturn'})\n",
    "\n",
    "df3 = get_index_dailyreturn('000300.SH',begin_day,end_day)\n",
    "df3 = df3.rename(columns={'dailyreturn':'hs300_dailyreturn'})\n",
    "\n",
    "df4 = get_median_dailyrertun_of_all_market(begin_day,end_day)\n",
    "\n",
    "df5 = get_special_index_return(institutions_baotuan_50_li,begin_day,end_day)\n",
    "df5 = df5.rename(columns={'special_index_mean_dailyreturn':'institutions_baotuan_50_mean_dailyreturn'})\n",
    "\n",
    "df6 = get_special_index_return(mao_40_li,begin_day,end_day)\n",
    "df6 = df6.rename(columns={'special_index_mean_dailyreturn':'mao_40_mean_dailyreturn'})\n",
    "\n",
    "df7 = get_all_market_amount(begin_day,end_day)\n",
    "\n",
    "# df8 = get_fin_sec_info('20160325','20210412')\n",
    "\n",
    "df9 = get_limit_up_down_number(begin_day,end_day)\n",
    "\n",
    "df10 = get_open_auction_amount(begin_day,end_day)\n",
    "\n",
    "df2 = df2.rename(columns={'datetime_str':'date'})\n",
    "df3 = df3.rename(columns={'datetime_str':'date'})\n",
    "df7['date'] = df7['date'].apply(lambda x:str(x).replace('-','').split(' ')[0])\n",
    "# df8['date'] = df8['date'].apply(lambda x: str(x))\n",
    "df9['date'] = df9['date'].apply(lambda x:str(x).replace('-','').split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df1,df2,on=['date'])\n",
    "for df in [df3,df4,df5,df6,df7,df9,df10]:\n",
    "    merged_all_df = pd.merge(merged_df,df,on=['date'],how='outer')\n",
    "    merged_df = merged_all_df\n",
    "merged_all_df = merged_all_df.sort_values(by='date',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_df = pd.read_pickle('index_monitor.pkl')\n",
    "update_df = ori_df.append(merged_all_df)\n",
    "update_df = update_df.sort_values(by='date',ascending=False)\n",
    "update_df = update_df.drop_duplicates(keep='first')\n",
    "update_df.to_pickle('index_monitor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
